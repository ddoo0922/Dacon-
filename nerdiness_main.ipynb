{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb3d238c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd02855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "from string import ascii_lowercase\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c75309b",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003ca335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 불러오기\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17101f44",
   "metadata": {},
   "source": [
    "# Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38fd420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 Answers와 secret 제외한 Q_Answers 정의\n",
    "Answers = []\n",
    "for i in range(1, 27):\n",
    "    Answers.append('Q' + str(i))\n",
    "    \n",
    "Q_Answers = []\n",
    "for i in range(1, 21):\n",
    "    Q_Answers.append('Q' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5978f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치 예측에 KNN 사용\n",
    "def knull(col):\n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    a = imputer.fit_transform(train[col])\n",
    "    train[col] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ff0d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knull(Answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eefce931",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Answers)):\n",
    "    test[Answers[i]]=test[Answers[i]].fillna(train[Answers[i]].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e58b8446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1~20번 항목 더해서 Q_score, 21~26번 항목 더해서 Qs_score 생성\n",
    "Q_secret= ['Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26']\n",
    "\n",
    "dataset = [train, test]\n",
    "\n",
    "for data in dataset:\n",
    "    data['Q_score'] = data[Q_Answers].sum(axis=1)\n",
    "    data['Qs_score'] = data[Q_secret].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bfa6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마키아벨리즘 테스트(1~20번 항목)에서 T, V, M 컬럼 생성\n",
    "for data in dataset:\n",
    "    data['T'] = data['Q1']+data['Q2']+data['Q3']+data['Q7']+data['Q10']+data['Q12']+data['Q15']+data['Q16'] \n",
    "    data['V'] = data['Q4']+data['Q5']+data['Q8']+data['Q11']+data['Q13']+data['Q20']\n",
    "    data['M'] = data['Q9']+data['Q19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c566a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마키아벨리즘 스코어, 분산 피처 생성\n",
    "for data in dataset:\n",
    "    data['Mach_score'] = data[Answers].mean(axis = 1)\n",
    "    data['Mach_var'] = data[Answers].var(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b31d256c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thdal\\AppData\\Local\\Temp/ipykernel_4252/4282676114.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['mach_%s_dv%s'%(a,b)] = data[a]/data[b]\n"
     ]
    }
   ],
   "source": [
    "# 마키아벨리즘 비율 피처 생성\n",
    "Ancoms = list(combinations(Answers, 2))\n",
    "for data in dataset:\n",
    "    for a,b in Ancoms:\n",
    "        data['mach_%s_dv%s'%(a,b)] = data[a]/data[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b155a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q drop\n",
    "for data in dataset:\n",
    "    data.drop([('Q'+str(i) )for i in range(1,27)], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57871520",
   "metadata": {},
   "source": [
    "# TIPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de20e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIPI = []\n",
    "for i in range(1,11):\n",
    "    TIPI.append('TIPI'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f4a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "knull(TIPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc540b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(TIPI)):\n",
    "    test[TIPI[i]]=test[TIPI[i]].fillna(train[TIPI[i]].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b01e1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp1~10 항목 사용해 Ex, Ag, Con, Es, Op 컬럼 만들기\n",
    "\n",
    "train['Extraverted'] = train['TIPI1']-train['TIPI6']\n",
    "train['Warm'] = train['TIPI7']-train['TIPI2']\n",
    "train['Dependable'] = train['TIPI3']-train['TIPI8']\n",
    "train['Calm'] = train['TIPI9']-train['TIPI4']\n",
    "train['OpenMind'] = train['TIPI5']-train['TIPI10']\n",
    "\n",
    "test['Extraverted'] = test['TIPI1']-test['TIPI6']\n",
    "test['Warm'] = test['TIPI7']-test['TIPI2']\n",
    "test['Dependable'] = test['TIPI3']-test['TIPI8']\n",
    "test['Calm'] = test['TIPI9']-test['TIPI4']\n",
    "test['OpenMind'] = test['TIPI5']-test['TIPI10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bafc2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp 비율 피처 생성\n",
    "tpcoms = list(combinations(TIPI, 2))\n",
    "\n",
    "for data in dataset:\n",
    "    for a,b in tpcoms:\n",
    "        data['%s_dv_%s'%(a,b)] = data[a]/data[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0814d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 TIPI drop\n",
    "train.drop([('TIPI'+str(i)) for i in range(1,10)], axis=1, inplace = True)\n",
    "train.drop('TIPI10', axis = 1, inplace = True)\n",
    "\n",
    "test.drop([('TIPI'+str(i)) for i in range(1,10)], axis=1, inplace = True)\n",
    "test.drop('TIPI10', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65c5ee",
   "metadata": {},
   "source": [
    "# Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c052321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index drop\n",
    "for data in dataset:\n",
    "    data.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f372a8e4",
   "metadata": {},
   "source": [
    "# Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac03345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#country 5개 구간으로 나누기\n",
    "def country_label(data):\n",
    "    nara = data['country'].copy()\n",
    "    nara_val = nara.value_counts()\n",
    "    \n",
    "    a = [] \n",
    "    b = []\n",
    "    c = [] \n",
    "    d = []\n",
    "    e = []\n",
    "\n",
    "    \n",
    "    for i in range(len(nara_val)):\n",
    "        if nara_val.values[i] <= 10 : a.append(nara_val.index[i])\n",
    "        elif 100>nara_val.values[i] >10 : b.append(nara_val.index[i])\n",
    "        elif 500>nara_val.values[i] >= 100 :c.append(nara_val.index[i])\n",
    "        elif 5000>nara_val.values[i] >= 500 :  d.append(nara_val.index[i])\n",
    "        elif nara_val.values[i] >= 5000 : e.append(nara_val.index[i])\n",
    "\n",
    "    for i in range(len(nara)):\n",
    "        if nara[i] in a: nara[i]=0\n",
    "        if nara[i] in b: nara[i]=1\n",
    "        if nara[i] in c: nara[i]=2\n",
    "        if nara[i] in d: nara[i]=3\n",
    "        if nara[i] in e: nara[i]=4\n",
    "\n",
    "        \n",
    "    nara.fillna(0, inplace = True)\n",
    "    return nara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "364a23bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['nara'] = country_label(train)\n",
    "test['nara'] = country_label(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae95c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['country'], axis=1)\n",
    "test = test.drop(columns=['country'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce7a1d",
   "metadata": {},
   "source": [
    "# VCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0fa5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCL = []\n",
    "for i in range(1,17):\n",
    "    VCL.append('VCL'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d0a6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#작성자의 영어 실력\n",
    "\n",
    "# 실제로 존재하고 쉬운단어\n",
    "VCL_1 = ['VCL1','VCL4','VCL5','VCL10','VCL14','VCL16']\n",
    "# 실제로 있는데 어려운 단어\n",
    "VCL_2 = ['VCL2','VCL3','VCL7','VCL8','VCL11','VCL13','VCL14']\n",
    "# 세상에 없는 단어\n",
    "VCL_3 = ['VCL6','VCL9','VCL12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74c8cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VCL score 생성\n",
    "\n",
    "dataset = [train,test]\n",
    "for data in dataset:\n",
    "    data['VCL_score'] = data[VCL].sum(axis=1)\n",
    "    data['VCL_3_score'] = data[VCL_3].sum(axis=1)\n",
    "    data.drop([('VCL'+str(i) )for i in range(1,17)], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b7f5b6",
   "metadata": {},
   "source": [
    "# Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7a56c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('hand', axis=1, inplace = True)\n",
    "test.drop('hand', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbbf1824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이상치 제거\n",
    "train = train.drop(train[train.familysize > 50].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03913cb6",
   "metadata": {},
   "source": [
    "# 결측치 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "908b3662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 데이터 결측치 대체\n",
    "knull(['familysize','religion','orientation','married','voted','nerdiness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d65f7",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed92e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 데이터의 age가 100이상인 값 이상치로 간주하고 제거\n",
    "train = train.drop(train[train.age > 100].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9174ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_cuts 연령대별 피처 생성\n",
    "def age_categorize(age):\n",
    "    age = (age // 10)\n",
    "    return age\n",
    "\n",
    "train['age_cuts'] = age_categorize(train['age'])\n",
    "test['age_cuts'] = age_categorize(test['age'])\n",
    "\n",
    "# 기존의 age drop하기\n",
    "train.drop('age', axis=1, inplace=True)\n",
    "test.drop('age', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80731fb",
   "metadata": {},
   "source": [
    "# Elapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "858e2ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapse = ['introelapse', 'testelapse', 'surveyelapse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c06576f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[elapse]=np.log1p(train[elapse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3be5f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#걸린시간 합\n",
    "train['elapse_sum'] = train['testelapse']+train['surveyelapse']\n",
    "test['elapse_sum'] = test['testelapse']+test['surveyelapse']\n",
    "\n",
    "train.drop('testelapse', axis=1, inplace = True)\n",
    "test.drop('testelapse', axis=1, inplace = True)\n",
    "\n",
    "train.drop('surveyelapse', axis=1, inplace = True)\n",
    "test.drop('surveyelapse', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e9b48",
   "metadata": {},
   "source": [
    "# ASD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9464b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASD 결측치 최빈값 대체\n",
    "train['ASD'] = train['ASD'].fillna(train['ASD'].mode()[0])\n",
    "test['ASD'] = test['ASD'].fillna(train['ASD'].mode()[0])\n",
    "\n",
    "#education 결측치 최빈값 대체\n",
    "train['education'] = train['education'].fillna(train['education'].mode()[0])\n",
    "test['education'] = test['education'].fillna(train['education'].mode()[0])\n",
    "\n",
    "#engnat 결측치 최빈값 대체\n",
    "train['engnat'] = train['engnat'].fillna(train['engnat'].mode()[0])\n",
    "test['engnat'] = test['engnat'].fillna(train['engnat'].mode()[0])\n",
    "\n",
    "#gender 결측치 최빈값 대체\n",
    "train['gender'] = train['gender'].fillna(train['gender'].mode()[0])\n",
    "test['gender'] = test['gender'].fillna(train['gender'].mode()[0])\n",
    "\n",
    "#religion 결측치 최빈값 대체\n",
    "test['religion'] = test['religion'].fillna(train['religion'].mode()[0])\n",
    "\n",
    "#orientation 결측치 최빈값 대체\n",
    "test['orientation'] = test['orientation'].fillna(train['orientation'].mode()[0])\n",
    "\n",
    "#voted 결측치 최빈값 대체\n",
    "test['voted'] = test['voted'].fillna(train['voted'].mode()[0])\n",
    "\n",
    "#married 결측치 최빈값 대체\n",
    "test['married'] = test['married'].fillna(train['married'].mode()[0])\n",
    "\n",
    "#familysize 결측치 최빈값 대체\n",
    "test['familysize'] = test['familysize'].fillna(train['familysize'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee609d1",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "282516c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "needenco = ['gender', 'religion', 'orientation']\n",
    "for i in needenco:\n",
    "    train[i] = encoder.fit_transform(train[i])\n",
    "    test[i] = encoder.transform(test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63f1dde",
   "metadata": {},
   "source": [
    "# Model 1: LGBM Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eaede339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 분리\n",
    "train_x = train.copy()\n",
    "train_x.drop('nerdiness', axis=1, inplace = True)\n",
    "train_y = train['nerdiness']\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c881ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM 1\n",
    "def lgbm_rfe_30(data_x, data_y, ratio=0.9, min_feats=40):\n",
    "    feats = data_x.columns.tolist()\n",
    "    archive = pd.DataFrame(columns=['model', 'n_feats', 'feats', 'score'])\n",
    "    while True:\n",
    "        model = LGBMClassifier(objective = 'binary', num_iterations=10**4)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(data_x[feats], data_y, random_state=30)\n",
    "        model.fit(x_train, y_train, eval_set = [(x_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = val_pred[:,1]\n",
    "        score = roc_auc_score(y_val, val_pred)\n",
    "        n_feats = len(feats)\n",
    "        print(n_feats, score)\n",
    "        archive = archive.append({'model':model, 'n_feats':n_feats, 'feats':feats, 'score':score}, ignore_index=True)\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=feats).sort_values(ascending=False)\n",
    "        next_n_feats = int(n_feats*ratio)\n",
    "        if next_n_feats < min_feats:\n",
    "            break\n",
    "        else:\n",
    "            feats = feat_imp.iloc[:next_n_feats].index.tolist()\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "701ebd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "#warnings.filterwarnings(action='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5db7d415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398 0.8524157335074692\n",
      "358 0.8446875860170657\n",
      "322 0.8497890098550365\n",
      "289 0.8442191349173718\n",
      "260 0.8493205587553425\n",
      "234 0.8517874850135957\n",
      "210 0.8437645041328501\n",
      "189 0.8478250854844077\n",
      "170 0.8528145071848363\n",
      "153 0.8452689030240002\n",
      "137 0.8479071436057433\n",
      "123 0.8455245788546876\n",
      "110 0.8444100280206891\n",
      "99 0.8449182125265033\n",
      "89 0.8465314463996351\n",
      "80 0.8458476287218396\n",
      "72 0.848468018063152\n",
      "64 0.8424835336703187\n",
      "57 0.8375148424426486\n",
      "51 0.8393451704332784\n",
      "45 0.8396751304580168\n",
      "40 0.8381551837122979\n"
     ]
    }
   ],
   "source": [
    "lgbm_30 = lgbm_rfe_30(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa46660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LGBMClassifier(objective=\"binary\", num_iterations=10**3)\n",
    "x_train_1 = train_x[lgbm_30.iloc[7,2]]\n",
    "model1.fit(x_train_1, train_y)\n",
    "\n",
    "pred_y1 = model1.predict_proba(test[lgbm_30.iloc[7,2]])\n",
    "pred_y1 = pred_y1[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35c8db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM 2\n",
    "def lgbm_rfe_500(data_x, data_y, ratio=0.9, min_feats=40):\n",
    "    feats = data_x.columns.tolist()\n",
    "    archive = pd.DataFrame(columns=['model', 'n_feats', 'feats', 'score'])\n",
    "    while True:\n",
    "        model = LGBMClassifier(objective = 'binary', num_iterations=10**4)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(data_x[feats], data_y, random_state=500)\n",
    "        model.fit(x_train, y_train, eval_set = [(x_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = val_pred[:,1]\n",
    "        score = roc_auc_score(y_val, val_pred)\n",
    "        n_feats = len(feats)\n",
    "        print(n_feats, score)\n",
    "        archive = archive.append({'model':model, 'n_feats':n_feats, 'feats':feats, 'score':score}, ignore_index=True)\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=feats).sort_values(ascending=False)\n",
    "        next_n_feats = int(n_feats*ratio)\n",
    "        if next_n_feats < min_feats:\n",
    "            break\n",
    "        else:\n",
    "            feats = feat_imp.iloc[:next_n_feats].index.tolist()\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3bb528a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398 0.8477122281224995\n",
      "358 0.848088356362889\n",
      "322 0.8469123422022236\n",
      "289 0.83966083220466\n",
      "260 0.8471833970124507\n",
      "234 0.8481801512826463\n",
      "210 0.8438017068081811\n",
      "189 0.8509111944770633\n",
      "170 0.8426554249642924\n",
      "153 0.84178972381853\n",
      "137 0.8467824437308689\n",
      "123 0.8408437742837975\n",
      "110 0.8434206712922069\n",
      "99 0.8457363280415583\n",
      "89 0.841245882218458\n",
      "80 0.841099241277462\n",
      "72 0.8376315294188286\n",
      "64 0.8266744490284171\n",
      "57 0.8423003691425893\n",
      "51 0.8369505727656595\n",
      "45 0.8363686276139901\n",
      "40 0.8324780240652794\n"
     ]
    }
   ],
   "source": [
    "lgbm_500 = lgbm_rfe_500(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68604cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LGBMClassifier(objective=\"binary\", num_iterations=10**3)\n",
    "x_train_2 = train_x[lgbm_500.iloc[14,2]]\n",
    "model2.fit(x_train_2, train_y)\n",
    "\n",
    "pred_y2 = model2.predict_proba(test[lgbm_500.iloc[14,2]])\n",
    "pred_y2 = pred_y2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2264760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM 3\n",
    "def lgbm_rfe_913(data_x, data_y, ratio=0.9, min_feats=40):\n",
    "    feats = data_x.columns.tolist()\n",
    "    archive = pd.DataFrame(columns=['model', 'n_feats', 'feats', 'score'])\n",
    "    while True:\n",
    "        model = LGBMClassifier(objective = 'binary', num_iterations=10**4)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(data_x[feats], data_y, random_state=913)\n",
    "        model.fit(x_train, y_train, eval_set = [(x_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = val_pred[:,1]\n",
    "        score = roc_auc_score(y_val, val_pred)\n",
    "        n_feats = len(feats)\n",
    "        print(n_feats, score)\n",
    "        archive = archive.append({'model':model, 'n_feats':n_feats, 'feats':feats, 'score':score}, ignore_index=True)\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=feats).sort_values(ascending=False)\n",
    "        next_n_feats = int(n_feats*ratio)\n",
    "        if next_n_feats < min_feats:\n",
    "            break\n",
    "        else:\n",
    "            feats = feat_imp.iloc[:next_n_feats].index.tolist()\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46f9c99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398 0.8535521747313413\n",
      "358 0.8549374697625225\n",
      "322 0.8497525001125786\n",
      "289 0.8563455691920085\n",
      "260 0.8542172549046776\n",
      "234 0.8566506862680574\n",
      "210 0.8528712180781722\n",
      "189 0.8527730725664819\n",
      "170 0.8501725051699592\n",
      "153 0.8524711307863997\n",
      "137 0.8544649279900607\n",
      "123 0.8481925638032424\n",
      "110 0.8540310670957357\n",
      "99 0.8546488064928451\n",
      "89 0.849245030084486\n",
      "80 0.8514371389544155\n",
      "72 0.85048483882775\n",
      "64 0.8436588184896906\n",
      "57 0.8432275555647928\n",
      "51 0.8454802837213545\n",
      "45 0.846106971679824\n",
      "40 0.8474033584239449\n"
     ]
    }
   ],
   "source": [
    "lgbm_913 = lgbm_rfe_913(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4b0745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = LGBMClassifier(objective=\"binary\", num_iterations=10**3)\n",
    "x_train_3 = train_x[lgbm_913.iloc[7,2]]\n",
    "model3.fit(x_train_3, train_y)\n",
    "\n",
    "pred_y3 = model3.predict_proba(test[lgbm_913.iloc[7,2]])\n",
    "pred_y3 = pred_y3[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8f1c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM 4\n",
    "def lgbm_rfe_8(data_x, data_y, ratio=0.9, min_feats=40):\n",
    "    feats = data_x.columns.tolist()\n",
    "    archive = pd.DataFrame(columns=['model', 'n_feats', 'feats', 'score'])\n",
    "    while True:\n",
    "        model = LGBMClassifier(objective = 'binary', num_iterations=10**4)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(data_x[feats], data_y, random_state=8)\n",
    "        model.fit(x_train, y_train, eval_set = [(x_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = val_pred[:,1]\n",
    "        score = roc_auc_score(y_val, val_pred)\n",
    "        n_feats = len(feats)\n",
    "        print(n_feats, score)\n",
    "        archive = archive.append({'model':model, 'n_feats':n_feats, 'feats':feats, 'score':score}, ignore_index=True)\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=feats).sort_values(ascending=False)\n",
    "        next_n_feats = int(n_feats*ratio)\n",
    "        if next_n_feats < min_feats:\n",
    "            break\n",
    "        else:\n",
    "            feats = feat_imp.iloc[:next_n_feats].index.tolist()\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "864d5af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398 0.8531349325320109\n",
      "358 0.8528316798018748\n",
      "322 0.8473145477456492\n",
      "289 0.848286909245877\n",
      "260 0.8457150044626397\n",
      "234 0.8472054227101834\n",
      "210 0.8449967894265881\n",
      "189 0.8501374401104577\n",
      "170 0.8438541354368044\n",
      "153 0.8474874247755183\n",
      "137 0.8474871376043722\n",
      "123 0.8494511010716079\n",
      "110 0.847056668056575\n",
      "99 0.8512752121907597\n",
      "89 0.8411963664809244\n",
      "80 0.8456320120014565\n",
      "72 0.8461517917756481\n",
      "64 0.8341308076056704\n",
      "57 0.8361048220630145\n",
      "51 0.8383464800283954\n",
      "45 0.8402165385309013\n",
      "40 0.8295768475730019\n"
     ]
    }
   ],
   "source": [
    "lgbm_8 = lgbm_rfe_8(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "14ed3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = LGBMClassifier(objective=\"binary\", num_iterations=10**3)\n",
    "x_train_4 = train_x[lgbm_8.iloc[8,2]]\n",
    "model4.fit(x_train_4, train_y)\n",
    "\n",
    "pred_y4 = model4.predict_proba(test[lgbm_8.iloc[8,2]])\n",
    "pred_y4 = pred_y4[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a62020",
   "metadata": {},
   "source": [
    "### LGBM Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b659afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = (pred_y1 + pred_y2 + pred_y3 + pred_y4) * (1/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378cb2c",
   "metadata": {},
   "source": [
    "# Model 2: ExtraTrees Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc969927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 분리\n",
    "train_x = train.copy()\n",
    "train_x.drop('nerdiness', axis=1, inplace = True)\n",
    "train_y = train['nerdiness']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1299fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 튜닝\n",
    "n_estimators = int(391.707369561944)\n",
    "max_depth = int(65.33353663762796)\n",
    "min_samples_split = int(5.797880430957836)\n",
    "min_samples_leaf = int(3.813420188476544)\n",
    "bootstrap = bootstrap = 0\n",
    "    \n",
    "assert type(n_estimators) == int\n",
    "assert type(max_depth) == int\n",
    "assert type(min_samples_split) == int\n",
    "assert type(min_samples_leaf) == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "571233dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Trees Regressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "xtree_tune = ExtraTreesRegressor(n_estimators=n_estimators,\n",
    "                               max_depth=max_depth,\n",
    "                               min_samples_split=min_samples_split,\n",
    "                               min_samples_leaf=min_samples_leaf,\n",
    "                               #max_features=max_features,\n",
    "                               bootstrap=bootstrap,\n",
    "                               oob_score=bootstrap,\n",
    "                               n_jobs=6,\n",
    "                               random_state=42,\n",
    "                               verbose=0)\n",
    "xtree_tune.fit(train_x, train_y)\n",
    "\n",
    "preds_tune = xtree_tune.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d733fd15",
   "metadata": {},
   "source": [
    "# Ensemble: Model1 + Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d82d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_ensemble = (preds_tune)*(0.75) + (pred_all)*(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0311dcb",
   "metadata": {},
   "source": [
    "# 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f726e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"nerdiness\" : pred_y_ensemble\n",
    "})\n",
    "submission.to_csv('sub_0826.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c455546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subb = pd.read_csv('sub_0826.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "15b2c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subb.rename(columns = {'Unnamed: 0' : 'index'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7af11bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subb.set_index('index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b8a89b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nerdiness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.140858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.783248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.899717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.718801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.912121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35447</th>\n",
       "      <td>0.938553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35448</th>\n",
       "      <td>0.728430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35449</th>\n",
       "      <td>0.965168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35450</th>\n",
       "      <td>0.108128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35451</th>\n",
       "      <td>0.738764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35452 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nerdiness\n",
       "index           \n",
       "0       0.140858\n",
       "1       0.783248\n",
       "2       0.899717\n",
       "3       0.718801\n",
       "4       0.912121\n",
       "...          ...\n",
       "35447   0.938553\n",
       "35448   0.728430\n",
       "35449   0.965168\n",
       "35450   0.108128\n",
       "35451   0.738764\n",
       "\n",
       "[35452 rows x 1 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "928c54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "subb.to_csv(\"sub_0826_lgbm_ext.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
